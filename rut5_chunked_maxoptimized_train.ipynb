{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1172dd-9f44-44ce-b3fd-0854ec8defc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.11/site-packages (0.14.0)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.45.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets sentencepiece torch accelerate peft bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0692f82-4311-46b2-b7d8-0b9cde686b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6701979b-ccb7-489f-a209-07a23fde49bd",
   "metadata": {},
   "source": [
    " –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f50ca1-5181-4d81-91e4-44a20a539afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ –î–æ—Å—Ç—É–ø–Ω–∞—è RAM: 52.52 –ì–ë | üéÆ –î–æ—Å—Ç—É–ø–Ω–∞—è VRAM: 11.66 –ì–ë\n",
      "üîπ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: 50000 –∑–∞–ø–∏—Å–µ–π\n",
      "‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ 5 —á–∞—Å—Ç–µ–π —Å —Ä–∞–∑–º–µ—Ä–æ–º —á–∞–Ω–∫–∞ 50000\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import torch\n",
    "\n",
    "def get_optimal_chunk_size(min_chunk_size=10000, max_chunk_size=50000):\n",
    "    \"\"\"\n",
    "    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–æ—Å—Ç—É–ø–Ω–æ–π –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏ (RAM) –∏ GPU-–ø–∞–º—è—Ç–∏ (VRAM).\n",
    "    \n",
    "    :param min_chunk_size: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 10 000 –∑–∞–ø–∏—Å–µ–π)\n",
    "    :param max_chunk_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 50 000 –∑–∞–ø–∏—Å–µ–π)\n",
    "    :return: –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞\n",
    "    \"\"\"\n",
    "    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—É—é –ø–∞–º—è—Ç—å (RAM) –≤ –ì–ë\n",
    "    total_ram = psutil.virtual_memory().available / (1024 ** 3)  # –í –ì–ë\n",
    "    \n",
    "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –≤–∏–¥–µ–æ–ø–∞–º—è—Ç—å (VRAM) –≤ –ì–ë, –µ—Å–ª–∏ –µ—Å—Ç—å GPU\n",
    "    if torch.cuda.is_available():\n",
    "        total_vram = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # –í –ì–ë\n",
    "    else:\n",
    "        total_vram = 0  # –ï—Å–ª–∏ GPU –Ω–µ—Ç, —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ VRAM = 0\n",
    "\n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞\n",
    "    estimated_chunk_size = int((total_ram + total_vram) * 2500)  # –ß–µ–º –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏, —Ç–µ–º –±–æ–ª—å—à–µ —á–∞–Ω–∫–∏\n",
    "\n",
    "    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º (min_chunk_size - max_chunk_size)\n",
    "    optimal_chunk_size = max(min(estimated_chunk_size, max_chunk_size), min_chunk_size)\n",
    "\n",
    "    print(f\"üíæ –î–æ—Å—Ç—É–ø–Ω–∞—è RAM: {total_ram:.2f} –ì–ë | üéÆ –î–æ—Å—Ç—É–ø–Ω–∞—è VRAM: {total_vram:.2f} –ì–ë\")\n",
    "    print(f\"üîπ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: {optimal_chunk_size} –∑–∞–ø–∏—Å–µ–π\")\n",
    "    \n",
    "    return optimal_chunk_size\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "df = pd.read_csv(\"output_final.csv\", sep=\";\").dropna()\n",
    "\n",
    "# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏\n",
    "if \"text_wich_errors\" in df.columns:\n",
    "    df.rename(columns={\"text_wich_errors\": \"text_with_errors\"}, inplace=True)\n",
    "\n",
    "# üìå –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –ø–µ—Ä–µ–¥ —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "chunk_size = get_optimal_chunk_size()\n",
    "\n",
    "# –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏ (—á–∞–Ω–∫–∏)\n",
    "for i, start in enumerate(range(0, len(df), chunk_size)):\n",
    "    df.iloc[start:start + chunk_size].to_csv(f\"chunk_{i + 1}.csv\", sep=\";\", index=False)\n",
    "\n",
    "print(f\"‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {i + 1} —á–∞—Å—Ç–µ–π —Å —Ä–∞–∑–º–µ—Ä–æ–º —á–∞–Ω–∫–∞ {chunk_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33b714-3e8a-4af7-8725-8b6ab0216cc2",
   "metadata": {},
   "source": [
    "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ (ruT5-large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217d7238-5b8e-44d5-89f1-263c9cc90ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ai-forever/ruT5-large\"\n",
    "\n",
    "# 8-–±–∏—Ç–Ω–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, legacy=False)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# –û—Ç–∫–ª—é—á–∞–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "model.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6929b-db8d-4a85-bccb-303f164340b0",
   "metadata": {},
   "source": [
    "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27905a2-ea4f-42f1-8dfb-eb9516497d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# –§–∏–∫—Å–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –æ–Ω–∏ –æ–±—É—á–∞–ª–∏—Å—å\n",
    "for param in model.parameters():\n",
    "    if param.dtype in [torch.float16, torch.float32]:\n",
    "        param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471db395-3ef3-434c-afe8-9b1979221c4a",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c6ef1d-b528-4e55-a330-de8d4f0737f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –§—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "def preprocess_data(example):\n",
    "    return {\n",
    "        \"input_text\": \"–ò—Å–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç: \" + example[\"text_with_errors\"],\n",
    "        \"target_text\": example[\"corrected_text\"]\n",
    "    }\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"target_text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcca8d3-9e79-4a2f-8268-c5facbe4f99c",
   "metadata": {},
   "source": [
    "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa686ea-8120-4fce-827a-5e15904569b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "checkpoint_dir = \"./ruT5-corrector-checkpoints\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=checkpoint_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    weight_decay=0.01,\n",
    "    bf16=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    label_names=[\"labels\"],\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    return {\"accuracy\": np.mean([p == l for p, l in zip(decoded_preds, decoded_labels)])}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e03ca-954f-4781-8ea5-9f2c05b68974",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418ca0dd-0471-4d69-ad3b-2f00b8c084f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ 1/5: chunk_1.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831b4b7f7cec41d7aa76ca201fb965a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40cb9289509407fbdbd62cbf6fbc9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430ea6f09b2e4d5c95f967693022e41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037aeafb566d4bf7b3a9e232a68b6598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2814' max='8436' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2814/8436 9:44:20 < 19:28:16, 0.08 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  32/5000 00:12 < 32:47, 2.52 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 11.66 GiB of which 2.02 GiB is free. Process 4495 has 27.63 MiB memory in use. Process 3613596 has 4.88 GiB memory in use. Process 3709684 has 4.64 GiB memory in use. Of the allocated memory 3.84 GiB is allocated by PyTorch, and 897.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m\n\u001b[1;32m     25\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     26\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     27\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å\u001b[39;00m\n\u001b[1;32m     38\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/checkpoint-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2639\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2639\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2643\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:3085\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3083\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 3085\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3086\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:3039\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 3039\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3040\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   3042\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:4105\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4102\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4104\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4106\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4115\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:4326\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4324\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((logits))\n\u001b[1;32m   4325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_eval_metrics \u001b[38;5;129;01mor\u001b[39;00m description \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 4326\u001b[0m         \u001b[43mall_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4328\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:317\u001b[0m, in \u001b[0;36mEvalLoopContainer.add\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mappend(tensors)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:129\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors)\n\u001b[1;32m    127\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:129\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors)\n\u001b[1;32m    127\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:131\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    134\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    135\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer_pt_utils.py:89\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     86\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m     92\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.02 GiB. GPU 0 has a total capacity of 11.66 GiB of which 2.02 GiB is free. Process 4495 has 27.63 MiB memory in use. Process 3613596 has 4.88 GiB memory in use. Process 3709684 has 4.64 GiB memory in use. Of the allocated memory 3.84 GiB is allocated by PyTorch, and 897.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —á–∞–Ω–∫–∞—Ö\n",
    "chunks = sorted([f for f in os.listdir() if f.startswith(\"chunk_\") and f.endswith(\".csv\")])\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\nüîπ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ {i + 1}/{len(chunks)}: {chunk}\")\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —á–∞–Ω–∫–∞\n",
    "    df_chunk = pd.read_csv(chunk, sep=\";\").dropna()\n",
    "    dataset = Dataset.from_pandas(df_chunk)\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "    dataset_split = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "    train_dataset = dataset_split[\"train\"]\n",
    "    test_dataset = dataset_split[\"test\"]\n",
    "\n",
    "    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö\n",
    "    train_dataset = train_dataset.map(preprocess_data)\n",
    "    test_dataset = test_dataset.map(preprocess_data)\n",
    "\n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º —Ç—Ä–µ–Ω–µ—Ä–∞\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "    trainer.train()\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å\n",
    "    trainer.save_model(f\"{checkpoint_dir}/checkpoint-{i + 1}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
